/**
 * OpenRouter APIæœåŠ¡
 * å¤„ç†ä¸OpenRouterå¤šæ¨¡å‹APIçš„äº¤äº’
 */
import dotenv from 'dotenv';
dotenv.config();

/**
 * èŠå¤©æ¶ˆæ¯æ¥å£
 */
export interface ChatMessage {
  role: 'user' | 'assistant' | 'system';
  content: string;
}

/**
 * èŠå¤©å®Œæˆè¯·æ±‚å‚æ•°
 */
export interface ChatCompletionRequest {
  model: string;
  messages: ChatMessage[];
  temperature?: number;
  max_tokens?: number;
}

/**
 * èŠå¤©å®Œæˆå“åº”
 */
export interface ChatCompletionResponse {
  choices: Array<{
    message: {
      content: string;
      role: string;
    };
  }>;
  model: string;
  usage?: {
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
}

/**
 * æ¨¡å‹ä¿¡æ¯æ¥å£
 */
export interface ModelInfo {
  id: string;
  name: string;
  provider: string;
}

/**
 * OpenRouteræœåŠ¡ç±»
 */
export class OpenRouterService {
  private apiKey: string;
  private baseUrl: string;
  private siteUrl: string;
  private siteName: string;

  constructor() {
    this.apiKey = process.env.OPENROUTER_API_KEY || '';
    this.baseUrl = process.env.OPENROUTER_URL || 'https://openrouter.ai/api/v1/chat/completions';
    this.siteUrl = process.env.SITE_URL || 'http://localhost:5173';
    this.siteName = process.env.SITE_NAME || 'Hi-RAG System';

    if (!this.apiKey) {
      throw new Error('OPENROUTER_API_KEYç¯å¢ƒå˜é‡æœªé…ç½®');
    }
  }

  /**
   * è°ƒç”¨OpenRouterèŠå¤©å®ŒæˆAPI
   */
  async chatCompletion(request: ChatCompletionRequest): Promise<ChatCompletionResponse> {
    console.log('ğŸ¤– è°ƒç”¨API:', request.model);

    try {
      const response = await fetch(this.baseUrl, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${this.apiKey}`,
          'HTTP-Referer': this.siteUrl,
          'X-Title': this.siteName,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: request.model,
          messages: request.messages,
          temperature: request.temperature || 0.7,
          max_tokens: request.max_tokens || 2000,
        }),
      });

      if (!response.ok) {
        const errorText = await response.text();
        console.error('âŒ APIé”™è¯¯:', response.status, response.statusText);
        throw new Error(`Openrouter APIé”™è¯¯: ${response.statusText} - ${errorText}`);
      }

      const data = await response.json();
      console.log('âœ… APIè°ƒç”¨æˆåŠŸ');

      return data;
    } catch (error) {
      console.error('ğŸ’¥ APIè°ƒç”¨å¤±è´¥:', error instanceof Error ? error.message : String(error));
      throw error;
    }
  }

  /**
   * è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
   */
  getAvailableModels(): ModelInfo[] {
    return [
      { id: 'openai/gpt-5-mini', name: 'GPT-5 Mini', provider: 'OpenAI' },
      { id: 'google/gemini-2.5-flash-lite', name: 'Gemini 2.5 Flash Lite', provider: 'Google' },
      { id: 'openai/gpt-4o-mini', name: 'GPT-4o Mini', provider: 'OpenAI' },
      { id: 'anthropic/claude-3.5-haiku', name: 'Claude 3.5 Haiku', provider: 'Anthropic' },
      { id: 'x-ai/grok-4', name: 'Grok 4', provider: 'X.AI' },
      { id: 'qwen/qwen3-235b-a22b-thinking-2507', name: 'Qwen3 235B Thinking', provider: 'Qwen' },
      { id: 'deepseek/deepseek-chat-v3-0324:free', name: 'DeepSeek Chat V3 (Free)', provider: 'DeepSeek' },
      // åŸæœ‰æ¨¡å‹
      { id: 'openai/gpt-4o', name: 'GPT-4o', provider: 'OpenAI' },
      { id: 'openai/gpt-3.5-turbo', name: 'GPT-3.5 Turbo', provider: 'OpenAI' },
      { id: 'anthropic/claude-3-opus', name: 'Claude 3 Opus', provider: 'Anthropic' },
      { id: 'anthropic/claude-3-sonnet', name: 'Claude 3 Sonnet', provider: 'Anthropic' },
      { id: 'anthropic/claude-3-haiku', name: 'Claude 3 Haiku', provider: 'Anthropic' },
      { id: 'google/gemini-pro', name: 'Gemini Pro', provider: 'Google' },
      { id: 'meta-llama/llama-2-70b-chat', name: 'Llama 2 70B', provider: 'Meta' },
    ];
  }
}

// åˆ›å»ºå•ä¾‹å®ä¾‹
let openRouterServiceInstance: OpenRouterService | null = null;

/**
 * è·å–OpenRouteræœåŠ¡å®ä¾‹
 */
export function getOpenRouterService(): OpenRouterService {
  if (!openRouterServiceInstance) {
    openRouterServiceInstance = new OpenRouterService();
  }
  return openRouterServiceInstance;
}

/**
 * ä¾¿æ·å‡½æ•°ï¼šè°ƒç”¨èŠå¤©å®ŒæˆAPI
 */
export async function chatCompletion(request: ChatCompletionRequest): Promise<ChatCompletionResponse> {
  const service = getOpenRouterService();
  return service.chatCompletion(request);
}

/**
 * ä¾¿æ·å‡½æ•°ï¼šè·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
 */
export function getAvailableModels(): ModelInfo[] {
  const service = getOpenRouterService();
  return service.getAvailableModels();
}



/**
 * å…³é”®è¯æå–è¯·æ±‚å‚æ•°
 */
export interface KeywordExtractionRequest {
  text: string;
  maxKeywords?: number;
}

/**
 * å…³é”®è¯æå–å“åº”
 */
export interface KeywordExtractionResponse {
  keywords: string[];
  originalText: string;
}

/**
 * ä½¿ç”¨GPT-5-miniè¿›è¡ŒæŸ¥è¯¢é‡å»º
 * @param request æŸ¥è¯¢é‡å»ºè¯·æ±‚å‚æ•°
 * @returns é‡å»ºåçš„æŸ¥è¯¢
 */


/**
 * ä½¿ç”¨GPT-5-miniè¿›è¡Œå…³é”®è¯æå–
 * @param request å…³é”®è¯æå–è¯·æ±‚å‚æ•°
 * @returns æå–çš„å…³é”®è¯
 */
export async function extractKeywordsWithGPT(request: KeywordExtractionRequest): Promise<KeywordExtractionResponse> {
  console.log('ğŸ” GPTå…³é”®è¯æå–...');
  
  try {
    const maxKeywords = request.maxKeywords || 6;
    
    const systemPrompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è¯­ä¹‰å…³é”®è¯æå–åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä»ç»™å®šæ–‡æœ¬ä¸­æå–å…³é”®è¯ï¼ŒåŒ…æ‹¬ç›´æ¥å‡ºç°çš„å…³é”®è¯å’Œè¯­ä¹‰ç›¸å…³çš„éšè—å…³é”®è¯ã€‚

æå–è§„åˆ™ï¼š
1. æå–${maxKeywords}ä¸ªæœ€é‡è¦çš„å…³é”®è¯
2. åŒ…å«ä¸¤ç±»å…³é”®è¯ï¼š
   - ç›´æ¥å…³é”®è¯ï¼šæ–‡æœ¬ä¸­æ˜ç¡®å‡ºç°çš„é‡è¦è¯æ±‡
   - éšè—å…³é”®è¯ï¼šé€šè¿‡è¯­ä¹‰æ¨ç†å¾—å‡ºçš„ç›¸å…³æ¦‚å¿µ
3. è¿›è¡Œè¯­ä¹‰æ‰©å±•å’Œæ¦‚å¿µæ¨ç†ï¼š
   - æ—¶é—´æ¦‚å¿µï¼šå¦‚"æ˜å¤©"è¦æ¨å¯¼å‡ºå…·ä½“æ—¥æœŸã€æ—¥ç¨‹å®‰æ’ç­‰
   - æ´»åŠ¨æ¦‚å¿µï¼šå¦‚"å®‰æ’"è¦æ¨å¯¼å‡ºä¼šè®®ã€ä»»åŠ¡ã€è®¡åˆ’ã€çº¦ä¼šç­‰
   - åœ°ç‚¹æ¦‚å¿µï¼šå¦‚"å…¬å¸"è¦æ¨å¯¼å‡ºåŠå…¬å®¤ã€å·¥ä½œåœºæ‰€ç­‰
   - äººç‰©æ¦‚å¿µï¼šå¦‚"åŒäº‹"è¦æ¨å¯¼å‡ºå›¢é˜Ÿã€åˆä½œç­‰
4. ä¼˜å…ˆæå–å…·ä½“çš„ã€æœ‰æœç´¢ä»·å€¼çš„è¯æ±‡
5. é¿å…æå–åœç”¨è¯ï¼ˆå¦‚ï¼šçš„ã€æ˜¯ã€åœ¨ã€æœ‰ç­‰ï¼‰
6. å…³é”®è¯ä¹‹é—´ç”¨é€—å·åˆ†éš”
7. åªè¿”å›å…³é”®è¯åˆ—è¡¨ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Š


ç¤ºä¾‹ï¼š
è¾“å…¥ï¼š"æˆ‘æ˜å¤©æœ‰ä»€ä¹ˆå®‰æ’"
è¾“å‡ºï¼šæ˜å¤©,æ—¥ç¨‹,å®‰æ’,ä¼šè®®,ä»»åŠ¡,è®¡åˆ’,çº¦ä¼š,å·¥ä½œ

ç¤ºä¾‹æ ¼å¼ï¼šå…³é”®è¯1,å…³é”®è¯2,å…³é”®è¯3`;

    const userPrompt = `è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–å…³é”®è¯ï¼š

"${request.text}"

è¯·æå–å…³é”®è¯ï¼š`;

    const chatRequest: ChatCompletionRequest = {
      model: 'openai/gpt-4o-mini',
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userPrompt }
      ],
      temperature: 0.2,
      max_tokens: 150
    };

    const response = await chatCompletion(chatRequest);
    const keywordsText = response.choices[0]?.message?.content?.trim() || '';
    
    // è§£æå…³é”®è¯
    const splitKeywords = keywordsText.split(/[,ï¼Œã€]/); // æ”¯æŒä¸­è‹±æ–‡é€—å·å’Œé¡¿å·
    const trimmedKeywords = splitKeywords.map(kw => kw.trim());
    const filteredKeywords = trimmedKeywords.filter(kw => kw.length > 0 && kw.length <= 20); // è¿‡æ»¤ç©ºå­—ç¬¦ä¸²å’Œè¿‡é•¿çš„è¯
    const keywords = filteredKeywords.slice(0, maxKeywords); // é™åˆ¶æ•°é‡
    
    console.log('âœ… å…³é”®è¯æå–å®Œæˆ');
    
    return {
      keywords,
      originalText: request.text
    };
  } catch (error) {
    console.error('âŒ å…³é”®è¯æå–å¤±è´¥:', error instanceof Error ? error.message : String(error));
    // å¤±è´¥æ—¶è¿”å›ç©ºæ•°ç»„
    return {
      keywords: [],
      originalText: request.text
    };
  }
}